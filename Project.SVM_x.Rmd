---
title: "SVM"
author: '35642114'
date: "2025-05-08"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

```{r}
library(ggpubr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(tidyr)
library(dplyr)
library(tidymodels)
library(glmnet)
library(janitor)
library(patchwork)
library(fairml)
library(tibble)
library(discrim)
library(rpart.plot)
library(rpart)
library(vip)
library(yardstick)
library(broom)

r2oos <- function(d, var) {
 rmse <- d |> rmse({{var}}, .pred) |> pull(.estimate) 
# mse <- rmse(d, var, .pred)$.estimate^2
 riv <- d |> rmse({{var}}, .pred_c) |> pull(.estimate)
# iv <- rmse(d, var, .pred_c)$.estimate^2 
 1 - (rmse * rmse) / (riv * riv)
}
svr_results_path<-"C:/Users/霍湘月/Desktop/p4-INLASPDE/results-R-svr"
```

```{r}
svr_results_path<-"C:/Users/霍湘月/Desktop/p4-INLASPDE/results-R-svr"
```

# ##svm_rbf
```{r}
#| label: svm_rbf -specification
set.seed(35642114)

svm_spec <- svm_rbf(cost=NULL, rbf_sigma=NULL, margin=NULL) |>
 set_mode("regression") |>
  set_engine("kernlab")

svm_wflow <- workflow() |>
  add_recipe(q2_recipe) |>
  add_model(svm_spec)

 svm_q2_fit <- fit(svm_wflow, q2_train)

q2_pred <- svm_q2_fit |>
  augment(q2_test) |>
  mutate(.pred_c = mean(q2_train$resp))

rmse(q2_pred, resp, .pred)
rsq (q2_pred, resp, .pred)
r2oos(q2_pred, resp)

svm_all_fit <- fit(svm_wflow, q2_data)
###VI
visp.svr<-vip(
  extract_fit_parsnip(svm_all_fit ),# extract model
  feature_names = names(q2_data%>% select(-resp)) ,
  method = "permute",
  train = q2_test,#data.frame
  target = "resp",# vector
  pred_wrapper = function(object, newdata) {
    as.vector(predict(object, newdata)) },# object:extract model; newdata:train
  metric = "rsq",
  keep = T,
   num_features = 8,
  geom = "point",
  nsim = 20# permute 30 times to stablize the outcome
)
visp.svr

ggsave(filename=paste0(svr_results_path, "/feature/VI.png"), plot = visp.svr, width = 6, height = 4, dpi = 300)
write.csv(visp.svr$data, file=paste0(svr_results_path, "/feature/VI.csv"))
```

```{r}
#| label: tuning-setup
# using all available cores

set.seed(35642114)

svm_tune_spec <- svm_rbf(cost=tune(), rbf_sigma=tune()) |>
  set_mode("regression") |>
  set_engine("kernlab")

svm_tune_wflow <- workflow() |>
  add_recipe(q2_recipe) |>
  add_model(svm_tune_spec)
```

# ################################Bayesian 

Using SVM method ,the main steps are as follows:

   1.Split the cwk2_q2_train_data into an 80% training set(q2_train) and an 20% testing set(q2_test).

   2.Tuning and Pruning:adjust hyper-parameters cost and rbf_sigma; Applying Cross-validation to search for the combination of hyper-parameters that minimises RMSE.

   3.Evaluate the tuned model by applying the workflow with the best hyperparameters (cost=8, rbf_sigma=0.007498942) to q2_split (retrain on q2_train, test on q2_test). Get the rsq(0.767879).

   4.Fit the final tuned workflow to the cwk2_q2_train_data,then predict the cwk2_q2_test_data.


In step 2, when I first tuned the SVM's ,I set rbf_sigma range=c(-4,1),
there was an error report in every fold when it was running: "A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0".
Then I narrowed the rbf_sigma range to exclude the extreme values that caused under or over smoothing. Afterwards, I iteratively refine both cost and rbf_sigma range by inspecting the RMSE or R_squared scatterplots (via autoplot()) while zooming in or zooming out around the regions with the best performance.

Note: because running SVM is very slow, I wrote the code "plan(multisession, workers = parallel::detectCores() - 1)" to increase the speed(by using all available cores) and "plan(sequential)" to restore the default state.




```{r}
#| label: Bayesian Opt
plan(multisession, workers =20)

start_time <- Sys.time()

library(ggplot2)
library(finetune)
library(glue)

# 定义参数范围（注意是 dials::parameters 类型）
svm_param <- parameters(cost(), rbf_sigma()) %>%
  update(
    cost = cost(range = log10(c(1, 8)), trans=log10_trans()),#对应于python log下的：采样从10^-2---10^6(默认做转换);等价于cost(range = c(-2, 6), trans = log10_trans())

    rbf_sigma = rbf_sigma(range = log10(c(0.005, 0.03)), trans=log10_trans()) # 10^-3---10^-1
    )

folds <- vfold_cv(q2_train, v = 5)

bayes_svm <- tune_bayes(
  svm_tune_wflow,
  resamples = folds,
  initial = 20  ,# 建立初始surrogate model, 随机抽的参数样本，加上param_info = svm_param指定在这个范围里面抽取
  iter = 50,  
  param_info = svm_param,     
  metrics = metric_set(rmse, rsq),
  control = control_bayes(verbose = TRUE)
)

metric<-show_best(bayes_svm, metric = "rsq")
autoplot1<-autoplot(bayes_svm, metric = "rsq") + theme_bw()
autoplot2<-autoplot(bayes_svm, metric = "rsq") +
  scale_x_continuous(
    labels = function(x) round(10^x, 3),  # 还原 log10 值为原始值
    name = "Cost (original scale)"
  ) +
  theme_bw()

autoplot<-ggarrange(autoplot1,autoplot2,
          nrow = 2, ncol = 1)

ggsave(filename=paste0(svr_results_path, "/feature/autoplot.png"), plot = autoplot, width = 6, height = 6, dpi = 300)
write.csv(metric, file=paste0(svr_results_path, "/feature/metric.csv"))


default_plan <- plan()
plan(sequential)
```

```{r}
#| label:  Retraining with the optimal hyperparameters combination  + VI
plan(multisession, workers =20)
set.seed(35642114)
BO_svm <- select_best(bayes_svm, metric = "rsq")

final_svm_fit <- svm_tune_wflow |>
 finalize_workflow(BO_svm) |>
 last_fit(q2_split)#train on the train_data,test on the test_data

collect_metrics(final_svm_fit)# last_fit()专用函数

###VI
visp.svr<-vip(
  extract_fit_parsnip(final_svm_fit ),# extract model
  feature_names = names(q2_data%>% select(-resp)) ,
  method = "permute",
  train = q2_test,#data.frame
  target = "resp",# vector
  pred_wrapper = function(object, newdata) {
    as.vector(predict(object, newdata)) },# object:extract model; newdata:train
  metric = "rsq",
  keep = T,
   num_features = 8,
  geom = "point",
  nsim = 20# permute 30 times to stablize the outcome
)
visp.svr

ggsave(filename=paste0(svr_results_path, "/feature/VI.png"), plot = visp.svr, width = 6, height = 4, dpi = 300)
write.csv(visp.svr$data, file=paste0(svr_results_path, "/feature/VI.csv"))

# Restore the default
plan(sequential)
```




















